test
plot(density(test$best_subset))
plot(density(test$lasso))
plot(density(test$pca))
plot(density(test$gb))
plot(density(test$svm))
plot(denisty(test$gb))
plot(density(test$svm))
plot(density(test$gb))
plot(density(test$svm))
plot(density(test$gb))
plot(density(test$svm))
plot(density(test$gb))
plot(density(test$svm))
plot(density(test$gb))
library(autoMrP)
?auto_MrP
vignette(package = "autoMrP")
devtools::build_vignettes()
browseVignettes("autoMrP")
library(autoMrP)
browseVignettes("autoMrP")
library(autoMrP)
browseVignettes("autoMrP")
library(autoMrP)
library(autoMrP)
browseVignettes()
library(autoMrP)
library(autoMrP)
library(autoMrP)
library(autoMrP)
library(autoMrP)
devtools::build_vignettes()
devtools::build_vignettes()
devtools::build_vignettes()
tools::showNonASCII(readLines("autoMrP_vignette.ltx"))
tools::showNonASCII(readLines("./vignettes/autoMrP_vignette.ltx"))
library(autoMrP)
library(autoMrP)
vignette("sandwich", package = "sandwich")
library(autoMrP)
library(autoMrP)
library(autoMrP)
library(autoMrP)
q()
parallel::detectCores(all.tests = TRUE)
?dplyr::sample_n()
library(autoMrP)
?dplyr::slice_sample()
rm(list=ls())
# arguments
seed <- NULL
y = "YES"
L1.x = c("L1x1", "L1x2", "L1x3")
L2.x = c("L2.x1", "L2.x2", "L2.x3", "L2.x4", "L2.x5", "L2.x6")
#L2.x = c("L2.x1", "L2.x2")
mrp.L2.x = NULL
L2.unit = "state"
L2.reg = "region"
L2.x.scale = TRUE
pcs = NULL
folds = NULL
bin.proportion = "proportion"
bin.size = NULL
survey = autoMrP::taxes_survey
census = autoMrP::taxes_census
ebma.size = 1/3
k.folds = 5
cv.sampling = "L2 units"
loss.unit = "individuals"
loss.fun = "MSE"
# switch for classifiers
best.subset = TRUE
lasso = FALSE
pca = TRUE
gb = FALSE
svm = FALSE
# the standard MRP model
mrp = TRUE
forward.select = FALSE
best.subset.L2.x = NULL
lasso.L2.x = NULL
pca.L2.x = NULL
gb.L2.x = NULL
svm.L2.x = NULL
# Standard MrP model L2 variables
gb.L2.unit = FALSE
gb.L2.reg = FALSE
# tuning params lasso
#lasso.lambda = list(c(0.1, 0.3, 1), c(1, 10, 10000))
lasso.lambda = seq(from = 0, to = 100, length.out = 15)
lasso.n.iter = 70
# tuning params boosting
gb.interaction.depth = c(1, 2, 3)
gb.shrinkage = c(0.04, 0.01, 0.008, 0.005, 0.001)
gb.n.trees.init = 1
gb.n.trees.increase = 50
gb.n.trees.max = 1000
gb.n.iter = 70
gb.n.minobsinnode = 5
svm.kernel = "radial"
svm.loss.fun = NULL
svm.gamma = c(0.3, 0.5, 0.55, 0.6, 0.65, 0.7, 0.8, 0.9, 1, 2, 3, 4)
svm.cost = c(1, 10)
ebma.n.draws = 1
ebma.tol = c(0.01, 0.005) # 0.001, 0.0005, 0.0001, 0.00005, 0.00001)
uncertainty = TRUE
boot.iter <- 2
seed = NULL
verbose = TRUE
cores = 6
svm.L2.reg = TRUE
svm.L2.unit = FALSE
# Call to function doing the error checks
error_checks(y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
L2.x.scale = L2.x.scale,
pcs = pcs,
folds = folds,
bin.proportion = bin.proportion,
bin.size = bin.size,
survey = survey,
census = census,
ebma.size = ebma.size,
k.folds = k.folds,
cv.sampling = cv.sampling,
loss.unit = loss.unit,
loss.fun = loss.fun,
best.subset = best.subset,
lasso = lasso,
pca = pca,
gb = gb,
svm = svm,
mrp = mrp,
forward.select = forward.select,
best.subset.L2.x = best.subset.L2.x,
lasso.L2.x = lasso.L2.x,
gb.L2.x = gb.L2.x,
svm.L2.x = svm.L2.x,
mrp.L2.x = mrp.L2.x,
gb.L2.unit = gb.L2.unit,
gb.L2.reg = gb.L2.reg,
lasso.lambda = lasso.lambda,
lasso.n.iter = lasso.n.iter,
uncertainty = uncertainty,
boot.iter = boot.iter,
seed = seed)
devtools::load_all()
# Call to function doing the error checks
error_checks(y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
L2.x.scale = L2.x.scale,
pcs = pcs,
folds = folds,
bin.proportion = bin.proportion,
bin.size = bin.size,
survey = survey,
census = census,
ebma.size = ebma.size,
k.folds = k.folds,
cv.sampling = cv.sampling,
loss.unit = loss.unit,
loss.fun = loss.fun,
best.subset = best.subset,
lasso = lasso,
pca = pca,
gb = gb,
svm = svm,
mrp = mrp,
forward.select = forward.select,
best.subset.L2.x = best.subset.L2.x,
lasso.L2.x = lasso.L2.x,
gb.L2.x = gb.L2.x,
svm.L2.x = svm.L2.x,
mrp.L2.x = mrp.L2.x,
gb.L2.unit = gb.L2.unit,
gb.L2.reg = gb.L2.reg,
lasso.lambda = lasso.lambda,
lasso.n.iter = lasso.n.iter,
uncertainty = uncertainty,
boot.iter = boot.iter,
seed = seed)
install.packages("qpdf")
# Call to function doing the error checks
error_checks(y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
L2.x.scale = L2.x.scale,
pcs = pcs,
folds = folds,
bin.proportion = bin.proportion,
bin.size = bin.size,
survey = survey,
census = census,
ebma.size = ebma.size,
k.folds = k.folds,
cv.sampling = cv.sampling,
loss.unit = loss.unit,
loss.fun = loss.fun,
best.subset = best.subset,
lasso = lasso,
pca = pca,
gb = gb,
svm = svm,
mrp = mrp,
forward.select = forward.select,
best.subset.L2.x = best.subset.L2.x,
lasso.L2.x = lasso.L2.x,
gb.L2.x = gb.L2.x,
svm.L2.x = svm.L2.x,
mrp.L2.x = mrp.L2.x,
gb.L2.unit = gb.L2.unit,
gb.L2.reg = gb.L2.reg,
lasso.lambda = lasso.lambda,
lasso.n.iter = lasso.n.iter,
uncertainty = uncertainty,
boot.iter = boot.iter,
seed = seed)
# Coerce individual-level variables and geographic variables to factors in
# survey and census data
survey <- survey %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), .funs = as.factor)
census <- census %>%
dplyr::mutate_at(.vars = c(L1.x, L2.unit, L2.reg), .funs = as.factor)
rm(list=ls())
# arguments
seed <- NULL
y = "YES"
L1.x = c("L1x1", "L1x2", "L1x3")
L2.x = c("L2.x1", "L2.x2", "L2.x3", "L2.x4", "L2.x5", "L2.x6")
#L2.x = c("L2.x1", "L2.x2")
mrp.L2.x = NULL
L2.unit = "state"
L2.reg = "region"
L2.x.scale = TRUE
pcs = NULL
folds = NULL
bin.proportion = "proportion"
bin.size = NULL
survey = autoMrP::taxes_survey
census = autoMrP::taxes_census
ebma.size = 1/3
k.folds = 5
cv.sampling = "L2 units"
loss.unit = "individuals"
loss.fun = "MSE"
# switch for classifiers
best.subset = TRUE
lasso = FALSE
pca = TRUE
gb = FALSE
svm = FALSE
# the standard MRP model
mrp = TRUE
forward.select = FALSE
best.subset.L2.x = NULL
lasso.L2.x = NULL
pca.L2.x = NULL
gb.L2.x = NULL
svm.L2.x = NULL
# Standard MrP model L2 variables
gb.L2.unit = FALSE
gb.L2.reg = FALSE
# tuning params lasso
#lasso.lambda = list(c(0.1, 0.3, 1), c(1, 10, 10000))
lasso.lambda = seq(from = 0, to = 100, length.out = 15)
lasso.n.iter = 70
# tuning params boosting
gb.interaction.depth = c(1, 2, 3)
gb.shrinkage = c(0.04, 0.01, 0.008, 0.005, 0.001)
gb.n.trees.init = 1
gb.n.trees.increase = 50
gb.n.trees.max = 1000
gb.n.iter = 70
gb.n.minobsinnode = 5
svm.kernel = "radial"
svm.loss.fun = NULL
svm.gamma = c(0.3, 0.5, 0.55, 0.6, 0.65, 0.7, 0.8, 0.9, 1, 2, 3, 4)
svm.cost = c(1, 10)
ebma.n.draws = 1
ebma.tol = c(0.01, 0.005) # 0.001, 0.0005, 0.0001, 0.00005, 0.00001)
uncertainty = TRUE
boot.iter <- 2
seed = NULL
verbose = TRUE
cores = 6
svm.L2.reg = TRUE
svm.L2.unit = FALSE
devtools::load_all()
# Call to function doing the error checks
error_checks(y = y,
L1.x = L1.x,
L2.x = L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
L2.x.scale = L2.x.scale,
pcs = pcs,
folds = folds,
bin.proportion = bin.proportion,
bin.size = bin.size,
survey = survey,
census = census,
ebma.size = ebma.size,
k.folds = k.folds,
cv.sampling = cv.sampling,
loss.unit = loss.unit,
loss.fun = loss.fun,
best.subset = best.subset,
lasso = lasso,
pca = pca,
gb = gb,
svm = svm,
mrp = mrp,
forward.select = forward.select,
best.subset.L2.x = best.subset.L2.x,
lasso.L2.x = lasso.L2.x,
gb.L2.x = gb.L2.x,
svm.L2.x = svm.L2.x,
mrp.L2.x = mrp.L2.x,
gb.L2.unit = gb.L2.unit,
gb.L2.reg = gb.L2.reg,
lasso.lambda = lasso.lambda,
lasso.n.iter = lasso.n.iter,
uncertainty = uncertainty,
boot.iter = boot.iter,
seed = seed)
# Check seed argument and set seed
if (is.null(seed)) { seed <- 546213978 }
set.seed(seed)
# Binding for global variables
`%>%` <- dplyr::`%>%`
idx_boot <- NULL
idx_boot
# Register cores
cl <- multicore(cores = cores, type = "open", cl = NULL)
cl
dplyr::slice_sample(.data = survey, n = base::nrow(survey), replace = TRUE)
# Estimate on 1 sample in autoMrP
boot_mrp <- auto_MrP(
survey = boot_sample,
ebma.n.draws = 1,
uncertainty = FALSE,
verbose = FALSE,
cores = 1,
y = y,
L1.x = L1.x,
L2.x = L2.x,
mrp.L2.x = mrp.L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
L2.x.scale = L2.x.scale,
pcs = pcs,
folds = folds,
bin.proportion = bin.proportion,
bin.size = bin.size,
census = census,
ebma.size = ebma.size,
k.folds = k.folds,
cv.sampling = cv.sampling,
loss.unit = loss.unit,
loss.fun = loss.fun,
best.subset = best.subset,
lasso = lasso,
pca = pca,
gb = gb,
svm = svm,
mrp = mrp,
forward.select = forward.select,
best.subset.L2.x = best.subset.L2.x,
lasso.L2.x = lasso.L2.x,
pca.L2.x = pca.L2.x,
gb.L2.x = gb.L2.x,
svm.L2.x = svm.L2.x,
gb.L2.unit = gb.L2.unit,
gb.L2.reg = gb.L2.reg,
lasso.lambda = lasso.lambda,
lasso.n.iter = lasso.n.iter,
gb.interaction.depth = gb.interaction.depth,
gb.shrinkage = gb.shrinkage,
gb.n.trees.init = gb.n.trees.init,
gb.n.trees.increase = gb.n.trees.increase,
gb.n.trees.max = gb.n.trees.max,
gb.n.iter = gb.n.iter,
gb.n.minobsinnode = gb.n.minobsinnode,
svm.kernel = svm.kernel,
svm.gamma = svm.gamma,
svm.cost = svm.cost,
ebma.tol = ebma.tol,
seed = seed,
boot.iter = NULL
)
# Bootstrapped survey sample
boot_sample <- dplyr::slice_sample(.data = survey, n = base::nrow(survey), replace = TRUE)
library(autoMrP)
# Estimate on 1 sample in autoMrP
boot_mrp <- auto_MrP(
survey = boot_sample,
ebma.n.draws = 1,
uncertainty = FALSE,
verbose = FALSE,
cores = 1,
y = y,
L1.x = L1.x,
L2.x = L2.x,
mrp.L2.x = mrp.L2.x,
L2.unit = L2.unit,
L2.reg = L2.reg,
L2.x.scale = L2.x.scale,
pcs = pcs,
folds = folds,
bin.proportion = bin.proportion,
bin.size = bin.size,
census = census,
ebma.size = ebma.size,
k.folds = k.folds,
cv.sampling = cv.sampling,
loss.unit = loss.unit,
loss.fun = loss.fun,
best.subset = best.subset,
lasso = lasso,
pca = pca,
gb = gb,
svm = svm,
mrp = mrp,
forward.select = forward.select,
best.subset.L2.x = best.subset.L2.x,
lasso.L2.x = lasso.L2.x,
pca.L2.x = pca.L2.x,
gb.L2.x = gb.L2.x,
svm.L2.x = svm.L2.x,
gb.L2.unit = gb.L2.unit,
gb.L2.reg = gb.L2.reg,
lasso.lambda = lasso.lambda,
lasso.n.iter = lasso.n.iter,
gb.interaction.depth = gb.interaction.depth,
gb.shrinkage = gb.shrinkage,
gb.n.trees.init = gb.n.trees.init,
gb.n.trees.increase = gb.n.trees.increase,
gb.n.trees.max = gb.n.trees.max,
gb.n.iter = gb.n.iter,
gb.n.minobsinnode = gb.n.minobsinnode,
svm.kernel = svm.kernel,
svm.gamma = svm.gamma,
svm.cost = svm.cost,
ebma.tol = ebma.tol,
seed = seed,
boot.iter = NULL
)
boot_mrp
library(autoMrP)
sessionInfo()
update.packages(ask = FALSE)
library(autoMrP)
sessionInfo()
browseVignettes(package = "autoMrP")
browseVignettes("autoMrP")
browseVignettes()
library(autoMrP)
browseVignettes()
devtools::install_github("retowuest/autoMrP", build_vignettes = TRUE)
install.packages("doRNG")
devtools::install_github("retowuest/autoMrP", build_vignettes = TRUE)
load("../../../Dropbox/MRP and ML/Replication JSS/autoMrP data objects/Section 3_3 Uncertainty Estimates.RData")
x = boot_out
algorithm = "ebma"
ci.lvl = 0.95
# L2.unit identifier
L2.unit <- names(x$classifiers)[1]
L2.unit
# plot classifier if EBMA was not estimated
if(x$ebma == "EBMA step skipped (only 1 classifier run)") {
algorithm <- names(x$classifiers)[-1]
}
# plot classifier if EBMA was not estimated
x$ebma
"EBMA step skipped (only 1 classifier run)" %in% x$ebma
"EBMA step skipped (only 1 classifier run)" %in% x$ebma
# plot classifier if EBMA was not estimated
if( "EBMA step skipped (only 1 classifier run)" %in% x$ebma ) {
algorithm <- names(x$classifiers)[-1]
}
plot(boot_out)
devtools::load_all()
devtools::load_all()
load("./../../../Dropbox/MRP and ML/Replication JSS/autoMrP data objects/Section 3_3 Uncertainty Estimates.RData")
plot(boot_out)
x = boot_out
algorithm = "mrp"
ci.lvl = 0.95
# L2.unit identifier
L2.unit <- names(x$classifiers)[1]
L2.unit
names(x$classifiers)
algorithm %in% names(x$classifiers)
stop('The ', algorithm, 'was not run. Re-run autoMrP with this algorithm. Allowed choices are: "ebma", "best_subset", "lasso", "pca", "gb", "svm", "mrp".')
stop('The ', algorithm, ' classifier was not run. Re-run autoMrP with this algorithm. Allowed choices are: "ebma", "best_subset", "lasso", "pca", "gb", "svm", "mrp".')
stop('The ', algorithm, ' classifier was not run. Re-run autoMrP with this algorithm. Allowed choices are: "ebma", "best_subset", "lasso", "pca", "gb", "svm", "mrp".')
stop('The ', algorithm, ' classifier was not run. Re-run autoMrP() with the requested algorithm. Allowed choices are: "ebma", "best_subset", "lasso", "pca", "gb", "svm", "mrp".')
stop('The ', algorithm, ' classifier was not run. Re-run autoMrP() with the requested algorithm. Allowed choices are: "ebma", "best_subset", "lasso", "pca", "gb", "svm", and "mrp".')
stop('The "', algorithm, '" classifier was not run. Re-run autoMrP() with the requested algorithm. Allowed choices are: "ebma", "best_subset", "lasso", "pca", "gb", "svm", and "mrp".')
devtools::install_github("retowuest/autoMrP")
devtools::install_github("retowuest/autoMrP", force = TRUE, build_vignettes = TRUE)
library(autoMrP)
?auto_MrP
