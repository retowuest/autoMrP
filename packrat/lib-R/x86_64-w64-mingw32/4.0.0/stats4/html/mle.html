<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Maximum Likelihood Estimation</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for mle {stats4}"><tr><td>mle {stats4}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Maximum Likelihood Estimation</h2>

<h3>Description</h3>

<p>Estimate parameters by the method of maximum likelihood.
</p>


<h3>Usage</h3>

<pre>
mle(minuslogl, start,
       optim = stats::optim,
       method = if(!useLim) "BFGS" else "L-BFGS-B",
       fixed = list(), nobs, lower, upper, ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>minuslogl</code></td>
<td>
<p>Function to calculate negative log-likelihood.</p>
</td></tr>
<tr valign="top"><td><code>start</code></td>
<td>
<p>Named list of vectors or single vector. Initial values
for optimizer. By default taken from the default arguments of <code>minuslogl</code></p>
</td></tr>
<tr valign="top"><td><code>optim</code></td>
<td>
<p>Optimizer function. (Experimental)</p>
</td></tr>
<tr valign="top"><td><code>method</code></td>
<td>
<p>Optimization method to use. See <code><a href="../../stats/html/optim.html">optim</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>fixed</code></td>
<td>
<p>Named list of vectors or single vector.  Parameter values to keep fixed during
optimization.</p>
</td></tr>
<tr valign="top"><td><code>nobs</code></td>
<td>
<p>optional integer: the number of observations, to be used for
e.g. computing <code><a href="../../stats/html/AIC.html">BIC</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>lower, upper</code></td>
<td>
<p>Named lists of vectors or single vectors. Bounds for <code><a href="../../stats/html/optim.html">optim</a></code>, if relevant.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>Further arguments to pass to <code><a href="../../stats/html/optim.html">optim</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>optim</code> optimizer is used to find the minimum of the
negative log-likelihood.  An approximate covariance matrix for the
parameters is obtained by inverting the Hessian matrix at the optimum.
By default,  <code><a href="../../stats/html/optim.html">optim</a></code> from the <code>stats</code> package is used; other
optimizers need to be plug-compatible, both with respect to arguments
and return values.
</p>
<p>The function <code>minuslogl</code> should take one or several arguments,
each of which can be a vector. The optimizer optimizes a function
which takes a single vector argument, containing the
concatenation of the arguments to <code>minuslogl</code>, removing any
values that should be held fixed. This function internally unpacks the
argument vector, inserts the fixed values and calls <code>minuslogl</code>.
</p>
<p>The vector arguments <code>start</code>, <code>fixed</code>, <code>upper</code>, and
<code>lower</code>, can be given in both packed and unpacked form, either as
a single vector or as a list of vectors. In the latter case, you only
need to specify those list elements that are actually affected. For vector
arguments, including those inside lists, use a default marker for
those values that you don't want to set: <code>NA</code> for <code>fixed</code>
and <code>start</code>, and <code>+Inf, -Inf</code> for <code>upper</code>, and
<code>lower</code>.
</p>


<h3>Value</h3>

<p>An object of class <code><a href="mle-class.html">mle-class</a></code>.
</p>


<h3>Note</h3>

<p>Notice that the <code>mll</code> argument should calculate -log L (not -2 log L). It
is for the user to ensure that the likelihood is correct, and that
asymptotic likelihood inference is valid.
</p>


<h3>See Also</h3>

<p><code><a href="mle-class.html">mle-class</a></code>
</p>


<h3>Examples</h3>

<pre>
## Avoid printing to unwarranted accuracy
od &lt;- options(digits = 5)

## Simulated EC50 experiment with count data
x &lt;- 0:10
y &lt;- c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8)

## Easy one-dimensional MLE:
nLL &lt;- function(lambda) -sum(stats::dpois(y, lambda, log = TRUE))
fit0 &lt;- mle(nLL, start = list(lambda = 5), nobs = NROW(y))

## sanity check --- notice that "nobs" must be input
## (not guaranteed to be meaningful for any likelihood)
stopifnot(nobs(fit0) == length(y))


# For 1D, this is preferable:
fit1 &lt;- mle(nLL, start = list(lambda = 5), nobs = NROW(y),
            method = "Brent", lower = 1, upper = 20)

## This needs a constrained parameter space: most methods will accept NA
ll &lt;- function(ymax = 15, xhalf = 6) {
    if(ymax &gt; 0 &amp;&amp; xhalf &gt; 0)
      -sum(stats::dpois(y, lambda = ymax/(1+x/xhalf), log = TRUE))
    else NA
}
(fit &lt;- mle(ll, nobs = length(y)))
mle(ll, fixed = list(xhalf = 6))

## Alternative using bounds on optimization
ll2 &lt;- function(ymax = 15, xhalf = 6)
    -sum(stats::dpois(y, lambda = ymax/(1+x/xhalf), log = TRUE))
mle(ll2, lower = rep(0, 2))

AIC(fit)
BIC(fit)

summary(fit)
logLik(fit)
vcov(fit)
plot(profile(fit), absVal = FALSE)
confint(fit)

## Use bounded optimization
## The lower bounds are really &gt; 0,
## but we use &gt;=0 to stress-test profiling
(fit2 &lt;- mle(ll2, lower = c(0, 0)))
plot(profile(fit2), absVal = FALSE)

## A better parametrization:
ll3 &lt;- function(lymax = log(15), lxhalf = log(6))
    -sum(stats::dpois(y, lambda = exp(lymax)/(1+x/exp(lxhalf)), log = TRUE))
(fit3 &lt;- mle(ll3))
plot(profile(fit3), absVal = FALSE)
exp(confint(fit3))

# Regression tests for bounded cases (this was broken in R 3.x)
fit4 &lt;- mle(ll, lower = c(0, 4)) # has max on boundary
confint(fit4)

## direct check that fixed= and constraints work together
mle(ll, lower = c(0, 4), fixed=list(ymax=23)) # has max on boundary

## Linear regression using MLE
x &lt;- 1:10 
y &lt;- c(0.48, 2.24, 2.22, 5.15, 4.64, 5.53, 7, 8.8, 7.67, 9.23)

LM_mll &lt;- function(formula, data = environment(formula))
{
     y &lt;- model.response(model.frame(formula, data))
     X &lt;- model.matrix(formula, data)
     b0 &lt;- numeric(NCOL(X))
     names(b0) &lt;- colnames(X)
     function(b=b0, sigma=1)
         -sum(dnorm(y, X %*% b, sigma, log=TRUE))
}

mll &lt;- LM_mll(y ~ x)

summary(lm(y~x)) # for comparison -- notice variance bias in MLE
summary(mle(mll, lower=c(-Inf,-Inf, 0.01)))
summary(mle(mll, lower=list(sigma = 0.01))) # alternative specification

confint(mle(mll, lower=list(sigma = 0.01)))
plot(profile(mle(mll, lower=list(sigma = 0.01))))

Binom_mll &lt;- function(x, n)
{
    force(x); force(n) ## beware lazy evaluation
    function(p=.5) -dbinom(x, n, p, log=TRUE)
}

## Likelihood functions for different x.
## This code goes wrong, if force(x) is not used in Binom_mll:

curve(Binom_mll(0, 10)(p), xname="p", ylim=c(0, 10))
mll_list &lt;- list(10)
for (x in 1:10)
    mll_list[[x]] &lt;- Binom_mll(x, 10)
for (mll in mll_list)
    curve(mll(p), xname="p", add=TRUE)

mll &lt;- Binom_mll(4,10)
mle(mll, lower = 1e-16, upper = 1-1e-16) # limits must be inside (0,1)

## Boundary case: This works, but fails if limits are set closer to 0 and 1  
mll &lt;- Binom_mll(0, 10)
mle(mll, lower=.005, upper=.995)

## Not run: 
## We can use limits closer to the boundaries if we use the
## drop-in replacement optimr() from the optimx package.

mle(mll, lower = 1e-16, upper = 1-1e-16, optim=optimx::optimr)

## End(Not run)


options(od)
</pre>

<hr /><div style="text-align: center;">[Package <em>stats4</em> version 4.0.0 <a href="00Index.html">Index</a>]</div>
</body></html>
